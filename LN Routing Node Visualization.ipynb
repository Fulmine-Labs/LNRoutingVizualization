{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c901da17-b9df-4e2c-8fd0-1054f876d165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method to access the transaction data of the routing node: RTL (LND or Eclair) or gRPC\n",
    "#data_access_method = \"gRPC\"\n",
    "data_access_method = \"RTL\"\n",
    "\n",
    "if (data_access_method == \"gRPC\"):\n",
    "\n",
    "    # Replace with your routing node's certificate, macaroon file path, server port and protobuf file location\n",
    "    cert_file = r'D:\\lnd\\node1\\tls.cert'\n",
    "    macaroon_file = r'D:\\lnd\\node1\\data\\chain\\bitcoin\\regtest\\admin.macaroon'\n",
    "    rpcserver = 'localhost:10009'\n",
    "    protobuf_file_location = r'D:\\lnd\\proto\\lnd\\lnrpc' # Location of generated Protobuf files\n",
    "    \n",
    "    import sys\n",
    "    # Ensure that this is the same version of Python that was used to generate the protobuf files\n",
    "    print (\"Ensure that this is the same version of Python that was used to generate the protobuf files\")\n",
    "    print(sys.executable)\n",
    "    print(sys.version)\n",
    "    \n",
    "    sys.path.append(protobuf_file_location)\n",
    "    \n",
    "    import grpc\n",
    "    import os\n",
    "    from google.protobuf.json_format import MessageToDict\n",
    "    from lightning_pb2 import ForwardingHistoryRequest\n",
    "    from lightning_pb2 import ChannelGraphRequest\n",
    "    from lightning_pb2 import GetInfoRequest\n",
    "    from lightning_pb2_grpc import LightningStub\n",
    "    \n",
    "elif (data_access_method == \"RTL\"):\n",
    "    \n",
    "    # Replace with the name of the Ride The Lightning Forwarding History CSV file\n",
    "    # Note: the provided 5 days of sample data has been anonymized for privacy. Using actual RTL node data will show the node ids\n",
    "    RTL_file = \"..\\Forwarding-history-eclair2.csv\"\n",
    "    #RTL_file = \"Forwarding-history-sample.csv\"\n",
    "else: \n",
    "    \n",
    "    print(\"Unsupported data access method.\", data_access_method, \" Must be gRPC or RTL\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395d0939-b65c-4ec7-b6e1-4e0993663455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ipycytoscape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58508482-4245-4859-b888-f15f8ab2ebce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_to_unix_timestamp(year, month, day, hour=0, minute=0, second=0):\n",
    "    \"\"\"Convert a date to a Unix timestamp.\"\"\"\n",
    "    dt = datetime.datetime(year, month, day, hour, minute, second)\n",
    "    return int(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da1f27d-b1c6-4a98-82ac-1024aa80e0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (data_access_method == \"gRPC\"):\n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    # Set the required date/time range for gRPC. Examples:\n",
    "    start = date_to_unix_timestamp(2023, 1, 1)  # January 1, 2023, at 00:00:00\n",
    "    end = date_to_unix_timestamp(2023, 12, 31, 23, 59, 59)  # January 31, 2023, at 23:59:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac8c2f0-beb9-4dac-8607-4a20a8176ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a gRPC channel with the LND routing node\n",
    "def create_grpc_channel(cert_file, macaroon_file):\n",
    "    try:\n",
    "        with open(cert_file, 'rb') as f:\n",
    "            cert = f.read()\n",
    "        with open(macaroon_file, 'rb') as f:\n",
    "            macaroon = f.read().hex()\n",
    "    \n",
    "        credentials = grpc.ssl_channel_credentials(cert)\n",
    "        channel = grpc.secure_channel('localhost:10009', credentials)\n",
    "        return channel, macaroon\n",
    "    except (FileNotFoundError, IOError) as e:\n",
    "        print(f\"Error reading cert or macaroon file: {e}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in creating gRPC channel: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f0a3f2-8084-44c3-a9d9-70359e55de7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_node_info(stub, macaroon):\n",
    "    try:\n",
    "        request = GetInfoRequest()\n",
    "        metadata = [('macaroon', macaroon)]\n",
    "        response = stub.GetInfo(request, metadata=metadata)\n",
    "        return response\n",
    "    except grpc.RpcError as e:\n",
    "        print(f\"gRPC error: {e.details()}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in fetching node info: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4511940c-784c-49b8-9e44-804d7611956d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get forwarding history\n",
    "def get_forwarding_history(stub, start_time, end_time, macaroon):\n",
    "    try:\n",
    "        # Create a request with the specified time range (in Unix timestamp)\n",
    "        request = ForwardingHistoryRequest(start_time=start_time, end_time=end_time, num_max_events=10000)\n",
    "        #request = ForwardingHistoryRequest()\n",
    "    \n",
    "        # Include the macaroon in the metadata\n",
    "        metadata = [('macaroon', macaroon)]\n",
    "\n",
    "        # Make the gRPC call\n",
    "        response = stub.ForwardingHistory(request, metadata=metadata)\n",
    "    \n",
    "        # Convert response to dictionary\n",
    "        events = [MessageToDict(event) for event in response.forwarding_events]\n",
    "    \n",
    "        # Return as pandas DataFrame\n",
    "        return pd.DataFrame(events)\n",
    "    except grpc.RpcError as e:\n",
    "        print(f\"gRPC error: {e.details()}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error getting forwarding history info: {e}\")\n",
    "        sys.exit(1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf990ce-3c9e-4b1c-9257-b7759623b50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_network_graph(stub, macaroon):\n",
    "    \n",
    "    try:\n",
    "        # Include the macaroon in the metadata\n",
    "        metadata = [('macaroon', macaroon)]\n",
    "    \n",
    "        request = ChannelGraphRequest(include_unannounced=True)\n",
    "        response = stub.DescribeGraph(request, metadata=metadata)\n",
    "        return response\n",
    "    except grpc.RpcError as e:\n",
    "        print(f\"gRPC error: {e.details()}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error while getting the network graph: {e}\")\n",
    "        sys.exit(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a0cb16-286a-4ece-aad4-2225bc98bfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_node_id_to_alias_map(graph):\n",
    "    node_id_to_alias = {}\n",
    "    for node in graph.nodes:\n",
    "        node_id_to_alias[node.pub_key] = node.alias\n",
    "    return node_id_to_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c843e6-6a4c-4444-a6f3-a1ca44d671aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_channel_id_to_node_ids_map(graph):\n",
    "    channel_id_to_node_ids = {}\n",
    "    for edge in graph.edges:\n",
    "        channel_id_to_node_ids[str(edge.channel_id)] = (edge.node1_pub, edge.node2_pub)\n",
    "    return channel_id_to_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927e7159-74a9-4545-862a-3cbb078aafe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_alias_for_channel(channel_id, channel_id_to_node_ids, node_id_to_alias, exclude_node_pub_key):\n",
    "    node_ids = channel_id_to_node_ids.get(str(channel_id), None)\n",
    "    if node_ids:\n",
    "        # Filter out the excluded node alias and return the other alias\n",
    "        aliases = [node_id_to_alias.get(node_id) for node_id in node_ids if node_id != exclude_node_pub_key]\n",
    "        if aliases:\n",
    "            return aliases[0]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69ecba0-2e42-48fc-924d-64391dd575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "\n",
    "        # Define the column name mappings for LND and Eclair\n",
    "        lnd_columns = {\n",
    "            'amt_in_msat': 'amt_in_msat',\n",
    "            'amt_out_msat': 'amt_out_msat',\n",
    "            'fee_msat': 'fee_msat',\n",
    "            'alias_in': 'alias_in',\n",
    "            'alias_out': 'alias_out'\n",
    "        }\n",
    "        eclair_columns = {\n",
    "            'amountIn': 'amt_in_msat',\n",
    "            'amountOut': 'amt_out_msat',\n",
    "            'fromChannelAlias': 'alias_in',\n",
    "            'toChannelAlias': 'alias_out'\n",
    "        }\n",
    "\n",
    "        # Detect the format (LND or Eclair) based on the column names\n",
    "        #print (df.columns)\n",
    "        if set(lnd_columns.keys()).issubset(df.columns):\n",
    "            column_map = lnd_columns\n",
    "        elif set(eclair_columns.keys()).issubset(df.columns):\n",
    "            column_map = eclair_columns\n",
    "            # Calculate fee_msat as the difference between amountIn and amountOut\n",
    "            df['fee_msat'] = df['amountIn'] - df['amountOut']\n",
    "        else:\n",
    "            raise ValueError(\"CSV format not recognized. Please ensure it's either LND or Eclair format.\")\n",
    "\n",
    "        # Rename the columns\n",
    "        df.rename(columns=column_map, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filepath} was not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: The file {filepath} is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: The file {filepath} does not appear to be a valid CSV or is improperly formatted.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9520d23e-bc56-4c7d-afe9-e99b2360cdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_nodes_and_edges(G, df):\n",
    "    \"\"\"Add nodes and edges to the graph G based on the dataframe df.\"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # Convert node names to strings to handle numerical aliases\n",
    "        u = str(row['alias_in'])\n",
    "        v = str(row['alias_out'])\n",
    "        \n",
    "        # Convert 'amt_out_msat' and 'fee_msat' to integers\n",
    "        weight = int(row['amt_out_msat'])\n",
    "        fee = int(row['fee_msat'])\n",
    "                \n",
    "        # Check if there's already an edge (i.e., a previous transaction between these channels)\n",
    "        if G.has_edge(u, v):\n",
    "            edge_data = G[u][v]\n",
    "            edge_data['weight'] += weight\n",
    "            edge_data['fees'].append(fee)\n",
    "        else:\n",
    "            G.add_edge(u, v, weight=weight, fees=[fee])\n",
    "    \n",
    "    # Average out the fees and compute total transactions\n",
    "    total_transactions = sum(nx.get_edge_attributes(G, 'weight').values())\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        d['avg_fee'] = sum(d['fees']) / len(d['fees'])\n",
    "        d['normalized_fee'] = d['avg_fee'] / total_transactions * 10000\n",
    "\n",
    "    return total_transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29696670-1a51-4977-9689-ce9a6b98a177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_classes_to_nodes(cyto_graph, df):\n",
    "    # Ensure numeric columns are of the correct type\n",
    "    df['fee_msat'] = pd.to_numeric(df['fee_msat'], errors='coerce').fillna(0)\n",
    "    df['amt_out_msat'] = pd.to_numeric(df['amt_out_msat'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Calculate total fees and total transactions for each node\n",
    "    total_fees = df.groupby('alias_out')['fee_msat'].sum()\n",
    "    total_transactions = df.groupby('alias_out')['amt_out_msat'].sum()\n",
    "\n",
    "    # Normalize the values\n",
    "    max_fee = total_fees.max()\n",
    "    max_transaction = total_transactions.max()\n",
    "    normalized_fees = total_fees / max_fee * 10000\n",
    "    normalized_transactions = total_transactions / max_transaction * 10000\n",
    "\n",
    "    # Adjust thresholds based on the distribution of your data\n",
    "    fee_thresholds = [100,5000]  # example thresholds for low, medium, high fee\n",
    "    transaction_thresholds = [500, 1000, 3000]  # example thresholds for tiny, small, medium, large transactions\n",
    "\n",
    "    # Iterate over nodes to assign classes\n",
    "    for node in cyto_graph.graph.nodes:\n",
    "        node_alias = node.data['id']\n",
    "        classes = []\n",
    "\n",
    "        # Assign fee classes based on normalized fees\n",
    "        fee = normalized_fees.get(node_alias, 0)\n",
    "        #print (node_alias, fee)\n",
    "        if fee == 0:\n",
    "            classes.append('no_fee')\n",
    "        elif fee <= fee_thresholds[0]:\n",
    "            classes.append('low_fee')\n",
    "        elif fee <= fee_thresholds[1]:\n",
    "            classes.append('medium_fee')\n",
    "        else:\n",
    "            classes.append('high_fee')\n",
    "\n",
    "        # Assign transaction size classes based on normalized transactions\n",
    "        trans = normalized_transactions.get(node_alias, 0)\n",
    "        #print (node_alias, trans)\n",
    "        if trans <= transaction_thresholds[0]:\n",
    "            classes.append('tiny_transaction')\n",
    "        elif trans <= transaction_thresholds[1]:\n",
    "            classes.append('small_transaction')\n",
    "        elif trans <= transaction_thresholds[2]:\n",
    "            classes.append('medium_transaction')\n",
    "        else:\n",
    "            classes.append('large_transaction')\n",
    "\n",
    "        node.classes = ' '.join(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "864e5f16-34dd-494c-8b9e-a5f78148f305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_classes_to_edges(cyto_graph, G, total_transactions):\n",
    "    # Normalize transactions for edges\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        d['weight'] = int(d.get('weight', 0))  # Convert to integer\n",
    "        d['normalized_transaction'] = d['weight'] / total_transactions * 10000\n",
    "\n",
    "    # Iterate over edges to assign classes\n",
    "    for edge in cyto_graph.graph.edges:\n",
    "        u, v = edge.data['source'], edge.data['target']\n",
    "        d = G[u][v]\n",
    "        \n",
    "        normalized_transaction = d['normalized_transaction']\n",
    "\n",
    "        if normalized_transaction < 1:\n",
    "            edge.classes = 'tiny_volume'\n",
    "        elif normalized_transaction < 10:\n",
    "            edge.classes = 'small_volume'\n",
    "        elif normalized_transaction < 100:\n",
    "            edge.classes = 'medium_volume'\n",
    "        else:\n",
    "            edge.classes = 'large_volume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7bdb24-6e52-4e96-b125-b2111636f7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set styles based on classes\n",
    "def set_styles (cyto_graph):\n",
    "    \n",
    "    cyto_graph.set_style([\n",
    "        {\n",
    "            'selector': 'node.no_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'red'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.low_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'orange'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.medium_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'yellow'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.high_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'green'\n",
    "            }\n",
    "        },\n",
    "            {\n",
    "            'selector': 'node.tiny_transaction',\n",
    "            'style': {\n",
    "                'width': '10px',\n",
    "                'height': '10px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.small_transaction',\n",
    "            'style': {\n",
    "                'width': '20px',\n",
    "                'height': '20px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.medium_transaction',\n",
    "            'style': {\n",
    "                'width': '30px',\n",
    "                'height': '30px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.large_transaction',\n",
    "            'style': {\n",
    "                'width': '50px',\n",
    "                'height': '50px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.tiny_volume',\n",
    "            'style': {\n",
    "                'width': '0px',\n",
    "                'line-color': 'grey'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.small_volume',\n",
    "            'style': {\n",
    "                'width': '1px',\n",
    "                'line-color': 'grey'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.medium_volume',\n",
    "            'style': {\n",
    "                'width': '2px',\n",
    "                'line-color': 'grey'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.large_volume',\n",
    "            'style': {\n",
    "                'width': '3px',\n",
    "                'line-color': 'black'\n",
    "            }\n",
    "        }\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2738b075-df32-4cd6-a286-44d593b0be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d455bd64d042e1a66a1870a8f19e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'circle'}, cytoscape_style=[{'selector': 'node.no_fee', 'style': {'câ€¦"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (data_access_method == \"RTL\"):\n",
    "    df = load_data (RTL_file)\n",
    "      \n",
    "else:\n",
    "\n",
    "    channel, macaroon = create_grpc_channel(cert_file, macaroon_file)\n",
    "    stub = LightningStub(channel)\n",
    "\n",
    "    # Extract the public key of the routing node\n",
    "    node_info = get_node_info(stub, macaroon)\n",
    "    routing_node_pub_key = node_info.identity_pubkey\n",
    "\n",
    "    # Fetch forwarding history\n",
    "    df = get_forwarding_history(stub, start, end, macaroon)\n",
    "\n",
    "    # Fetch the graph and create the maps\n",
    "    graph = get_network_graph(stub, macaroon)\n",
    "\n",
    "    node_id_to_alias = create_node_id_to_alias_map(graph)\n",
    "    channel_id_to_node_ids = create_channel_id_to_node_ids_map(graph)\n",
    "\n",
    "    # Exclude the routing node itself from the network graph\n",
    "    exclude_node_pub_key = routing_node_pub_key\n",
    "\n",
    "    # When applying the aliases to the DataFrame\n",
    "    df['alias_in'] = df['chanIdIn'].apply(lambda x: get_alias_for_channel(x, channel_id_to_node_ids, node_id_to_alias, exclude_node_pub_key))\n",
    "    df['alias_out'] = df['chanIdOut'].apply(lambda x: get_alias_for_channel(x, channel_id_to_node_ids, node_id_to_alias, exclude_node_pub_key))\n",
    "\n",
    "    # ALign the column names returned from gRPC with the CSV column names\n",
    "    df = df.rename(columns={\n",
    "    'feeMsat': 'fee_msat',\n",
    "    'amtInMsat': 'amt_in_msat',\n",
    "    'amtOutMsat': 'amt_out_msat',\n",
    "    'timestampNs': 'timestamp_ns'\n",
    "    })\n",
    "\n",
    "# Check if the data was loaded successfully\n",
    "if df is None:\n",
    "    # If df is None, print an error message and exit\n",
    "    print(\"Transaction data could not be loaded. Please check the file path and format or API connection.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Create a new Cytograph\n",
    "G = nx.Graph()\n",
    "\n",
    "total_transactions = add_nodes_and_edges(G, df)\n",
    "\n",
    "cyto_graph = ipycytoscape.CytoscapeWidget()\n",
    "cyto_graph.graph.add_graph_from_networkx(G)\n",
    "\n",
    "cyto_graph.set_layout(name='circle')\n",
    "\n",
    "assign_classes_to_nodes (cyto_graph, df)\n",
    "assign_classes_to_edges (cyto_graph, G, total_transactions)\n",
    "\n",
    "set_styles (cyto_graph)\n",
    "\n",
    "# Note: \n",
    "# Ensure that ipytoscape is enabled in Jupyter Lab or Jupyter Notebook, in a Conda shell run the following\n",
    "# jupyter nbextension enable --py --sys-prefix ipycytoscape\n",
    "# Start Jupyter with \"jupyter notebook (or jupyter lab) --NotebookApp.iopub_data_rate_limit=1.0e10\", in Powershell if datarate is exceeded\n",
    "# This can happen with large numbers of transactions\n",
    "\n",
    "cyto_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a516a0-ea48-4fbc-8299-7b14e815b275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576595c-f3ca-4d3e-aa2a-925b8a33a8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
