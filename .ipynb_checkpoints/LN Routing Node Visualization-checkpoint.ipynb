{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c901da17-b9df-4e2c-8fd0-1054f876d165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensure that this is the same version of Python that was used to generate the protobuf files\n",
      "C:\\Users\\Duncan\\anaconda3\\envs\\myenv\\python.exe\n",
      "3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Method to access the transaction data of the routing node: RTL or gRPC\n",
    "data_access_method = \"gRPC\"\n",
    "#data_access_method = \"RTL\"\n",
    "\n",
    "if (data_access_method == \"gRPC\"):\n",
    "\n",
    "    # Replace with your routing node's certificate, macaroon file path, server port and protobuf file location\n",
    "    cert_file = r'D:\\lnd\\node1\\tls.cert'\n",
    "    macaroon_file = r'D:\\lnd\\node1\\data\\chain\\bitcoin\\regtest\\admin.macaroon'\n",
    "    rpcserver = 'localhost:10009'\n",
    "    protobuf_file_location = r'D:\\lnd\\proto\\lnd\\lnrpc' # Location of generated Protobuf files\n",
    "    \n",
    "    import sys\n",
    "    # Ensure that this is the same version of Python that was used to generate the protobuf files\n",
    "    print (\"Ensure that this is the same version of Python that was used to generate the protobuf files\")\n",
    "    print(sys.executable)\n",
    "    print(sys.version)\n",
    "    \n",
    "    sys.path.append(protobuf_file_location)\n",
    "    \n",
    "    import grpc\n",
    "    import os\n",
    "    from google.protobuf.json_format import MessageToDict\n",
    "    from lightning_pb2 import ForwardingHistoryRequest\n",
    "    from lightning_pb2 import ChannelGraphRequest\n",
    "    from lightning_pb2 import GetInfoRequest\n",
    "    from lightning_pb2_grpc import LightningStub\n",
    "    \n",
    "elif (data_access_method == \"RTL\"):\n",
    "    \n",
    "    # Replace with the name of the Ride The Lightning Forwarding History CSV file\n",
    "    # Note: the provided 5 days of sample data has been anonymized for privacy. Using actual RTL node data will show the node ids\n",
    "    RTL_file = \"Forwarding-history-sample.csv\"\n",
    "    \n",
    "else: \n",
    "    \n",
    "    print(\"Unsupported data access method.\", data_access_method, \" Must be gRPC or RTL\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395d0939-b65c-4ec7-b6e1-4e0993663455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ipycytoscape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58508482-4245-4859-b888-f15f8ab2ebce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_to_unix_timestamp(year, month, day, hour=0, minute=0, second=0):\n",
    "    \"\"\"Convert a date to a Unix timestamp.\"\"\"\n",
    "    dt = datetime.datetime(year, month, day, hour, minute, second)\n",
    "    return int(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da1f27d-b1c6-4a98-82ac-1024aa80e0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (data_access_method == \"gRPC\"):\n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    # Set the required date/time range for gRPC. Examples:\n",
    "    start = date_to_unix_timestamp(2023, 1, 1)  # January 1, 2023, at 00:00:00\n",
    "    end = date_to_unix_timestamp(2023, 12, 31, 23, 59, 59)  # January 31, 2023, at 23:59:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac8c2f0-beb9-4dac-8607-4a20a8176ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a gRPC channel with the LND node\n",
    "def create_grpc_channel(cert_file, macaroon_file):\n",
    "    with open(cert_file, 'rb') as f:\n",
    "        cert = f.read()\n",
    "    with open(macaroon_file, 'rb') as f:\n",
    "        macaroon = f.read().hex()\n",
    "\n",
    "    credentials = grpc.ssl_channel_credentials(cert)\n",
    "    channel = grpc.secure_channel('localhost:10009', credentials)\n",
    "    return channel, macaroon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f0a3f2-8084-44c3-a9d9-70359e55de7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get node information\n",
    "def get_node_info(stub, macaroon):\n",
    "    request = GetInfoRequest()\n",
    "    metadata = [('macaroon', macaroon)]\n",
    "    response = stub.GetInfo(request, metadata=metadata)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4511940c-784c-49b8-9e44-804d7611956d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get forwarding history\n",
    "def get_forwarding_history(stub, start_time, end_time, macaroon):\n",
    "    # Create a request with the specified time range (in Unix timestamp)\n",
    "    request = ForwardingHistoryRequest(start_time=start_time, end_time=end_time, num_max_events=10000)\n",
    "    #request = ForwardingHistoryRequest(start_time=start_time, end_time=end_time)\n",
    "    #request = ForwardingHistoryRequest()\n",
    "    \n",
    "    # Include the macaroon in the metadata\n",
    "    metadata = [('macaroon', macaroon)]\n",
    "\n",
    "    # Make the gRPC call\n",
    "    response = stub.ForwardingHistory(request, metadata=metadata)\n",
    "    \n",
    "    # Convert response to dictionary\n",
    "    events = [MessageToDict(event) for event in response.forwarding_events]\n",
    "    \n",
    "    # Return as pandas DataFrame\n",
    "    return pd.DataFrame(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf990ce-3c9e-4b1c-9257-b7759623b50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_network_graph(stub, macaroon):\n",
    "    \n",
    "    # Include the macaroon in the metadata\n",
    "    metadata = [('macaroon', macaroon)]\n",
    "    \n",
    "    request = ChannelGraphRequest(include_unannounced=True)\n",
    "    response = stub.DescribeGraph(request, metadata=metadata)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a0cb16-286a-4ece-aad4-2225bc98bfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_node_id_to_alias_map(graph):\n",
    "    node_id_to_alias = {}\n",
    "    for node in graph.nodes:\n",
    "        node_id_to_alias[node.pub_key] = node.alias\n",
    "    return node_id_to_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c843e6-6a4c-4444-a6f3-a1ca44d671aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_channel_id_to_node_ids_map(graph):\n",
    "    channel_id_to_node_ids = {}\n",
    "    for edge in graph.edges:\n",
    "        channel_id_to_node_ids[str(edge.channel_id)] = (edge.node1_pub, edge.node2_pub)\n",
    "    return channel_id_to_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927e7159-74a9-4545-862a-3cbb078aafe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_alias_for_channel(channel_id, channel_id_to_node_ids, node_id_to_alias, exclude_node_pub_key):\n",
    "    node_ids = channel_id_to_node_ids.get(str(channel_id), None)\n",
    "    if node_ids:\n",
    "        # Filter out the excluded node alias and return the other alias\n",
    "        aliases = [node_id_to_alias.get(node_id) for node_id in node_ids if node_id != exclude_node_pub_key]\n",
    "        if aliases:\n",
    "            return aliases[0]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69ecba0-2e42-48fc-924d-64391dd575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RTL data from the CSV file\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        # Attempt to read the CSV file\n",
    "        return pd.read_csv(filepath, encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the file doesn't exist\n",
    "        print(f\"Error: The file {filepath} was not found.\")\n",
    "        return None\n",
    "    except PermissionError:\n",
    "        # Handle the case where the file exists but you don't have the permission to open it\n",
    "        print(f\"Error: Permission denied when trying to read the file {filepath}.\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        # Handle the case where the file is empty\n",
    "        print(f\"Error: The file {filepath} is empty.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError:\n",
    "        # Handle the case where the file has parsing issues\n",
    "        print(f\"Error: The file {filepath} does not appear to be a valid CSV or is improperly formatted.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Handle any other exception and print out a message\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9520d23e-bc56-4c7d-afe9-e99b2360cdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_nodes_and_edges(G, df):\n",
    "    \"\"\"Add nodes and edges to the graph G based on the dataframe df.\"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # Convert node names to strings to handle numerical aliases\n",
    "        u = str(row['alias_in'])\n",
    "        v = str(row['alias_out'])\n",
    "        \n",
    "        # Convert 'amt_out_msat' and 'fee_msat' to integers\n",
    "        weight = int(row['amt_out_msat'])\n",
    "        fee = int(row['fee_msat'])\n",
    "                \n",
    "        # Check if there's already an edge (i.e., a previous transaction between these channels)\n",
    "        if G.has_edge(u, v):\n",
    "            edge_data = G[u][v]\n",
    "            edge_data['weight'] += weight\n",
    "            edge_data['fees'].append(fee)\n",
    "        else:\n",
    "            G.add_edge(u, v, weight=weight, fees=[fee])\n",
    "    \n",
    "    # Average out the fees and compute total transactions\n",
    "    total_transactions = sum(nx.get_edge_attributes(G, 'weight').values())\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        d['avg_fee'] = sum(d['fees']) / len(d['fees'])\n",
    "        d['normalized_fee'] = d['avg_fee'] / total_transactions * 10000\n",
    "\n",
    "    return total_transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29696670-1a51-4977-9689-ce9a6b98a177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign classes to nodes based on normalized transactions and fees\n",
    "def assign_classes_to_nodes (cyto_graph, df):\n",
    "    \n",
    "    # Ensure numeric columns are of the correct type\n",
    "    df['fee_msat'] = pd.to_numeric(df['fee_msat'], errors='coerce')\n",
    "    df['amt_out_msat'] = pd.to_numeric(df['amt_out_msat'], errors='coerce')\n",
    "\n",
    "    for node in cyto_graph.graph.nodes:\n",
    "        node_alias = node.data['id']\n",
    "        \n",
    "        classes = []\n",
    "        \n",
    "        # # Calculate total fees and total transactions for each node\n",
    "        total_fees = df.groupby('alias_out')['fee_msat'].sum()\n",
    "        total_transactions_gr = df.groupby('alias_out')['amt_out_msat'].sum()\n",
    "\n",
    "        max_transaction = total_transactions_gr.max()\n",
    "\n",
    "        # Normalize the transactions\n",
    "        normalized_transactions_node = (total_transactions_gr / max_transaction).to_dict()\n",
    "        normalized_fees = (total_fees / total_transactions_gr * 10000).to_dict()\n",
    "\n",
    "        # Assign fee classes\n",
    "        if node_alias in normalized_fees:\n",
    "            \n",
    "            fee = normalized_fees[node_alias]\n",
    "            if fee <= 0.1:\n",
    "                classes.append('low_fee')\n",
    "            elif fee <= 0.2:\n",
    "                classes.append('medium_fee')\n",
    "            else:\n",
    "                classes.append('high_fee')\n",
    "        else:\n",
    "            classes.append('no_fee')\n",
    "\n",
    "        # Assign transaction classes\n",
    "        if node_alias in normalized_transactions_node:\n",
    "            trans = normalized_transactions_node[node_alias]\n",
    "            if trans <= 0.1:\n",
    "                classes.append('tiny_transaction')\n",
    "            elif trans <= 0.5:\n",
    "                classes.append('small_transaction')\n",
    "            elif trans <= 0.9:\n",
    "                classes.append('medium_transaction')\n",
    "            else:\n",
    "                classes.append('large_transaction')\n",
    "\n",
    "        # Combine classes with space\n",
    "        node.classes = ' '.join(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "864e5f16-34dd-494c-8b9e-a5f78148f305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign classes to edges based on normalized transaction volumes\n",
    "def assign_classes_to_edges (cyto_graph, G, total_transactions):\n",
    "\n",
    "    for edge in cyto_graph.graph.edges:\n",
    "\n",
    "        u, v = edge.data['source'], edge.data['target']   \n",
    "        d = G[u][v]\n",
    "\n",
    "        normalized_transaction = d['weight']/total_transactions * 10000\n",
    "\n",
    "        if (normalized_transaction < 1):\n",
    "            edge.classes = 'tiny_volume'\n",
    "        elif normalized_transaction < 10:\n",
    "            edge.classes = 'small_volume'\n",
    "        elif normalized_transaction < 100:\n",
    "            edge.classes = 'medium_volume'\n",
    "        else:\n",
    "            edge.classes = 'large_volume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7bdb24-6e52-4e96-b125-b2111636f7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set styles based on classes\n",
    "def set_styles (cyto_graph):\n",
    "    \n",
    "    cyto_graph.set_style([\n",
    "        {\n",
    "            'selector': 'node.no_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'red'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.low_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'orange'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.medium_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'yellow'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.high_fee',\n",
    "            'style': {\n",
    "                'content': 'data(id)',\n",
    "                'background-color': 'green'\n",
    "            }\n",
    "        },\n",
    "            {\n",
    "            'selector': 'node.tiny_transaction',\n",
    "            'style': {\n",
    "                'width': '10px',\n",
    "                'height': '10px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.small_transaction',\n",
    "            'style': {\n",
    "                'width': '20px',\n",
    "                'height': '20px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.medium_transaction',\n",
    "            'style': {\n",
    "                'width': '30px',\n",
    "                'height': '30px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'node.large_transaction',\n",
    "            'style': {\n",
    "                'width': '50px',\n",
    "                'height': '50px'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.tiny_volume',\n",
    "            'style': {\n",
    "                'width': '0px',\n",
    "                'line-color': 'grey'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.small_volume',\n",
    "            'style': {\n",
    "                'width': '1px',\n",
    "                'line-color': 'grey'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.medium_volume',\n",
    "            'style': {\n",
    "                'width': '2px',\n",
    "                'line-color': 'grey'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'selector': 'edge.large_volume',\n",
    "            'style': {\n",
    "                'width': '3px',\n",
    "                'line-color': 'black'\n",
    "            }\n",
    "        }\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2738b075-df32-4cd6-a286-44d593b0be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c147a972c4e044fe9c723b76baaff6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'circle'}, cytoscape_style=[{'selector': 'node.no_fee', 'style': {'câ€¦"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (data_access_method == \"RTL\"):\n",
    "    df = load_data (RTL_file)\n",
    "      \n",
    "else:\n",
    "\n",
    "    channel, macaroon = create_grpc_channel(cert_file, macaroon_file)\n",
    "    stub = LightningStub(channel)\n",
    "\n",
    "    # Extract the public key of the routing node\n",
    "    node_info = get_node_info(stub, macaroon)\n",
    "    routing_node_pub_key = node_info.identity_pubkey\n",
    "\n",
    "    # Fetch forwarding history\n",
    "    df = get_forwarding_history(stub, start, end, macaroon)\n",
    "\n",
    "    # Fetch the graph and create the maps\n",
    "    graph = get_network_graph(stub, macaroon)\n",
    "\n",
    "    node_id_to_alias = create_node_id_to_alias_map(graph)\n",
    "    channel_id_to_node_ids = create_channel_id_to_node_ids_map(graph)\n",
    "\n",
    "    # Exclude the routing node itself from the network graph\n",
    "    exclude_node_pub_key = routing_node_pub_key\n",
    "\n",
    "    # When applying the aliases to the DataFrame\n",
    "    df['alias_in'] = df['chanIdIn'].apply(lambda x: get_alias_for_channel(x, channel_id_to_node_ids, node_id_to_alias, exclude_node_pub_key))\n",
    "    df['alias_out'] = df['chanIdOut'].apply(lambda x: get_alias_for_channel(x, channel_id_to_node_ids, node_id_to_alias, exclude_node_pub_key))\n",
    "\n",
    "    # ALign the column names returned from gRPC with the CSV column names\n",
    "    df = df.rename(columns={\n",
    "    'feeMsat': 'fee_msat',\n",
    "    'amtInMsat': 'amt_in_msat',\n",
    "    'amtOutMsat': 'amt_out_msat',\n",
    "    'timestampNs': 'timestamp_ns'\n",
    "    })\n",
    "\n",
    "# Check if the data was loaded successfully\n",
    "if df is None:\n",
    "    # If df is None, print an error message and exit\n",
    "    print(\"Transaction data could not be loaded.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Create a new Cytograph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Check if the data was loaded successfully\n",
    "if df is None:\n",
    "    # If df is None, print an error message and exit\n",
    "    print(\"Transaction data could not be loaded. Please check the file path and format or API connection.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "total_transactions = add_nodes_and_edges(G, df)\n",
    "\n",
    "cyto_graph = ipycytoscape.CytoscapeWidget()\n",
    "cyto_graph.graph.add_graph_from_networkx(G)\n",
    "\n",
    "cyto_graph.set_layout(name='circle')\n",
    "\n",
    "assign_classes_to_nodes (cyto_graph, df)\n",
    "assign_classes_to_edges (cyto_graph, G, total_transactions)\n",
    "\n",
    "set_styles (cyto_graph)\n",
    "\n",
    "# Note: \n",
    "# Ensure that ipytoscape is enabled in Jupyter Lab or Jupyter Notebook, in a Conda shell run the following\n",
    "# jupyter nbextension enable --py --sys-prefix ipycytoscape\n",
    "# Start Jupyter with \"jupyter notebook (or jupyter lab) --NotebookApp.iopub_data_rate_limit=1.0e10\", in Powershell if datarate is exceeded\n",
    "# This can happen with large numbers of transactions\n",
    "\n",
    "cyto_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a516a0-ea48-4fbc-8299-7b14e815b275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576595c-f3ca-4d3e-aa2a-925b8a33a8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
